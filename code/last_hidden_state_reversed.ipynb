{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veron\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from eval_faiss import *\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = pd.read_csv('./test_data/test_rdkit_canonical.csv', sep='\\t')\n",
    "kekulize = pd.read_csv('./test_data/test_kekulize_smiles.csv', sep='\\t')\n",
    "explicit_hs = pd.read_csv('./test_data/test_explicit_hs.csv', sep='\\t')\n",
    "cycle = pd.read_csv('./test_data/test_cycle_renumering.csv', sep='\\t')\n",
    "gold = pd.read_csv('./test_data/test_original.csv', sep='\\t')\n",
    "\n",
    "full_data = {'canonical': canonical, 'explicit_hs': explicit_hs, 'kekulize': kekulize, 'cycle': cycle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tokenizer, full_data=full_data):\n",
    "    \n",
    "    try:\n",
    "        orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "    except:\n",
    "        print('model mode')\n",
    "        orig_res = save_last_hidden_state_model(gold, model, tokenizer, 'orig')\n",
    "\n",
    "\n",
    "\n",
    "    for key, value in full_data.items():\n",
    "        try:\n",
    "            test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "        except:\n",
    "            print('model mode')\n",
    "            test = save_last_hidden_state_model(value, model, tokenizer, key)\n",
    "        x = create_dist(orig_res, test)\n",
    "        print(key)\n",
    "        print('top1: ', sum(x[-2]))\n",
    "        print('top5: ', sum(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at laituan245/molt5-base-smiles2caption were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 3886.90it/s]\n",
      "100%|██████████| 3300/3300 [06:04<00:00,  9.05it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 6247.58it/s]\n",
      "100%|██████████| 3300/3300 [05:14<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1371\n",
      "top5:  1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4139.85it/s]\n",
      "100%|██████████| 3300/3300 [09:52<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  58\n",
      "top5:  115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 6410.72it/s]\n",
      "100%|██████████| 3300/3300 [05:33<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  2014\n",
      "top5:  2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 7054.15it/s]\n",
      "100%|██████████| 3300/3300 [05:37<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3148\n",
      "top5:  3255\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"laituan245/molt5-base-smiles2caption\")\n",
    "model = AutoModel.from_pretrained('laituan245/molt5-base-smiles2caption')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5567.64it/s]\n",
      "100%|██████████| 3300/3300 [04:58<00:00, 11.07it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 6112.97it/s]\n",
      "100%|██████████| 3300/3300 [04:52<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1531\n",
      "top5:  2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4615.77it/s]\n",
      "100%|██████████| 3300/3300 [08:09<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  71\n",
      "top5:  124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 7119.85it/s]\n",
      "100%|██████████| 3300/3300 [04:53<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  2161\n",
      "top5:  2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3461.42it/s]\n",
      "100%|██████████| 3300/3300 [05:04<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3265\n",
      "top5:  3297\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-standard\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-standard')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3835.23it/s]\n",
      "100%|██████████| 3300/3300 [05:00<00:00, 11.00it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5500.66it/s]\n",
      "100%|██████████| 3300/3300 [04:54<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1487\n",
      "top5:  2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4357.42it/s]\n",
      "100%|██████████| 3300/3300 [08:29<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  91\n",
      "top5:  187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5699.08it/s]\n",
      "100%|██████████| 3300/3300 [04:33<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  2207\n",
      "top5:  2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5910.85it/s]\n",
      "100%|██████████| 3300/3300 [04:35<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3251\n",
      "top5:  3287\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 3919.51it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4349.99it/s]\n",
      "100%|██████████| 3300/3300 [02:09<00:00, 25.43it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4552.24it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4527.66it/s]\n",
      "100%|██████████| 3300/3300 [02:04<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  851\n",
      "top5:  1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3346.92it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3032.03it/s]\n",
      "100%|██████████| 3300/3300 [03:25<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  29\n",
      "top5:  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4374.15it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4065.27it/s]\n",
      "100%|██████████| 3300/3300 [02:14<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1424\n",
      "top5:  2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4120.11it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4351.69it/s]\n",
      "100%|██████████| 3300/3300 [02:14<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3200\n",
      "top5:  3290\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "model = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5391.21it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 6102.85it/s]\n",
      "100%|██████████| 3300/3300 [12:53<00:00,  4.27it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5575.02it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5877.58it/s]\n",
      "100%|██████████| 3300/3300 [12:17<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1159\n",
      "top5:  1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3825.20it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4368.13it/s]\n",
      "100%|██████████| 3300/3300 [43:41<00:00,  1.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  43\n",
      "top5:  78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 1072.19it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 1019.10it/s]\n",
      "100%|██████████| 3300/3300 [42:48<00:00,  1.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1773\n",
      "top5:  2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:02<00:00, 1287.59it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:02<00:00, 1543.71it/s]\n",
      "100%|██████████| 3300/3300 [44:45<00:00,  1.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3292\n",
      "top5:  3300\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mschuh/PubChemDeBERTa-augmented\")\n",
    "model = AutoModel.from_pretrained('mschuh/PubChemDeBERTa-augmented')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at entropy/roberta_zinc_480m were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at entropy/roberta_zinc_480m and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3300/3300 [00:04<00:00, 779.83it/s] \n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:04<00:00, 744.04it/s]\n",
      "100%|██████████| 3300/3300 [34:41<00:00,  1.59it/s]\n",
      "100%|██████████| 3300/3300 [00:03<00:00, 1009.83it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 860.55it/s] \n",
      "100%|██████████| 3300/3300 [34:45<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  813\n",
      "top5:  1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:04<00:00, 660.50it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:04<00:00, 697.22it/s]\n",
      "100%|██████████| 3300/3300 [34:07<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  34\n",
      "top5:  58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:02<00:00, 1221.03it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:02<00:00, 1192.67it/s]\n",
      "100%|██████████| 3300/3300 [34:51<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1133\n",
      "top5:  1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 831.34it/s] \n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 904.10it/s] \n",
      "100%|██████████| 3300/3300 [34:11<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3138\n",
      "top5:  3273\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"entropy/roberta_zinc_480m\", max_len=128)# размерности тензоров не совпадают\n",
    "model = AutoModel.from_pretrained('entropy/roberta_zinc_480m')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at laituan245/molt5-large-smiles2caption were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3300/3300 [00:03<00:00, 1003.93it/s]\n",
      "100%|██████████| 3300/3300 [7:41:48<00:00,  8.40s/it]     \n",
      "100%|██████████| 3300/3300 [00:03<00:00, 944.16it/s] \n",
      "100%|██████████| 3300/3300 [27:52<00:00,  1.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1656\n",
      "top5:  2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3156.07it/s]\n",
      "100%|██████████| 3300/3300 [29:52<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  50\n",
      "top5:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4478.93it/s]\n",
      "100%|██████████| 3300/3300 [16:14<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1895\n",
      "top5:  2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4138.81it/s]\n",
      "100%|██████████| 3300/3300 [16:52<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3291\n",
      "top5:  3300\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"laituan245/molt5-large-smiles2caption\")\n",
    "model = AutoModel.from_pretrained('laituan245/molt5-large-smiles2caption')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at entropy/gpt2_zinc_87m were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3300/3300 [00:01<00:00, 3190.87it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3532.27it/s]\n",
      "100%|██████████| 3300/3300 [38:04<00:00,  1.44it/s]\n",
      "100%|██████████| 3300/3300 [00:05<00:00, 561.38it/s] \n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 1014.41it/s]\n",
      "100%|██████████| 3300/3300 [17:23<00:00,  3.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  826\n",
      "top5:  1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3208.28it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3293.39it/s]\n",
      "100%|██████████| 3300/3300 [08:23<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  23\n",
      "top5:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3666.39it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3568.59it/s]\n",
      "100%|██████████| 3300/3300 [07:33<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1212\n",
      "top5:  1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:03<00:00, 842.92it/s] \n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:04<00:00, 709.28it/s] \n",
      "100%|██████████| 3300/3300 [05:00<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  2707\n",
      "top5:  2944\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"entropy/gpt2_zinc_87m\", max_len=256) # ids out of range \n",
    "model = AutoModel.from_pretrained('entropy/gpt2_zinc_87m')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jonghyunlee/ChemBERT_ChEMBL_pretrained and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3300/3300 [01:13<00:00, 44.80it/s]\n",
      "100%|██████████| 3300/3300 [01:05<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  828\n",
      "top5:  1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:19<00:00, 41.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  34\n",
      "top5:  68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:10<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1136\n",
      "top5:  1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:12<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  2825\n",
      "top5:  3010\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jonghyunlee/ChemBERT_ChEMBL_pretrained\", max_len=128) #256 max_length=128\n",
    "model = AutoModel.from_pretrained('jonghyunlee/ChemBERT_ChEMBL_pretrained')\n",
    "\n",
    "orig_res = save_last_hidden_state_bert(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_bert(value['SMILES'], model, tokenizer, key)\n",
    "    x = create_dist(orig_res, test)\n",
    "    print(key)\n",
    "    print('top1: ', sum(x[-2]))\n",
    "    print('top5: ', sum(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [14:38<00:00,  3.76it/s]\n",
      "100%|██████████| 3300/3300 [13:14<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  831\n",
      "top5:  1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [22:40<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  26\n",
      "top5:  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [13:33<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  1200\n",
      "top5:  1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [13:48<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  2423\n",
      "top5:  2711\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gayane/BARTSmiles\", trust_remote_code=True, max_len=128)\n",
    "model = AutoModel.from_pretrained(\"gayane/BARTSmiles\", trust_remote_code=True)\n",
    "\n",
    "orig_res = save_last_hidden_state_bert(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_bert(value['SMILES'], model, tokenizer, key)\n",
    "    x = create_dist(orig_res, test)\n",
    "    print(key)\n",
    "    print('top1: ', sum(x[-2]))\n",
    "    print('top5: ', sum(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 3665.74it/s]\n",
      "100%|██████████| 3300/3300 [12:08<00:00,  4.53it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4980.07it/s]\n",
      "100%|██████████| 3300/3300 [04:32<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1733\n",
      "top5:  2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3700.73it/s]\n",
      "100%|██████████| 3300/3300 [07:33<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  95\n",
      "top5:  211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3306.63it/s]\n",
      "100%|██████████| 3300/3300 [04:30<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  2346\n",
      "top5:  2870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3022.42it/s]\n",
      "100%|██████████| 3300/3300 [09:50<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3270\n",
      "top5:  3298\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-standard\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-standard')\n",
    "model.eval()\n",
    "\n",
    "gold['SMILES'] = ['Caption the following SMILES: '+i for i in gold['SMILES']]\n",
    "orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    value['SMILES'] = ['Caption the following SMILES: '+i for i in value['SMILES']]\n",
    "    test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "    x = create_dist(orig_res, test)\n",
    "    print(key)\n",
    "    print('top1: ', sum(x[-2]))\n",
    "    print('top5: ', sum(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3864.49it/s]\n",
      "100%|██████████| 3300/3300 [06:21<00:00,  8.64it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 3612.28it/s]\n",
      "100%|██████████| 3300/3300 [05:17<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "top1:  1669\n",
      "top5:  2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 2702.40it/s]\n",
      "100%|██████████| 3300/3300 [08:24<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "top1:  128\n",
      "top5:  296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3923.91it/s]\n",
      "100%|██████████| 3300/3300 [05:16<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "top1:  2353\n",
      "top5:  2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3348.99it/s]\n",
      "100%|██████████| 3300/3300 [06:31<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "top1:  3265\n",
      "top5:  3299\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-augm\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "model.eval()\n",
    "\n",
    "gold['SMILES'] = ['Caption the following SMILES: '+i for i in gold['SMILES']]\n",
    "orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    value['SMILES'] = ['Caption the following SMILES: '+i for i in value['SMILES']]\n",
    "    test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "    x = create_dist(orig_res, test)\n",
    "    print(key)\n",
    "    print('top1: ', sum(x[-2]))\n",
    "    print('top5: ', sum(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
