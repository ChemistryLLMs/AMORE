{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMORE\n",
    "### How to evaluate models using last hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veron\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from eval_faiss import *\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import libs and ```eval_faiss.py```. Then upload data and put it into ```full_data``` dict. Use augmentations that you need, you can evaluate models on all of them or on the choosed ones. If you prefer to use your own augmentations, also add them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = pd.read_csv('./test_data/test_rdkit_canonical.csv', sep='\\t')\n",
    "kekulize = pd.read_csv('./test_data/test_kekulize_smiles.csv', sep='\\t')\n",
    "explicit_hs = pd.read_csv('./test_data/test_explicit_hs.csv', sep='\\t')\n",
    "cycle = pd.read_csv('./test_data/test_cycle_renumering.csv', sep='\\t')\n",
    "gold = pd.read_csv('./test_data/test_original.csv', sep='\\t')\n",
    "\n",
    "full_data = {'canonical': canonical, 'explicit_hs': explicit_hs, 'kekulize': kekulize, 'cycle': cycle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngold = pd.read_csv('./datasets/isomers/smiles_qm9_isomers_found_new.csv', sep='\\t')\\n\\ncanonical = pd.read_csv('./datasets/isomers/isomers_rdkit_canonical.csv', sep='\\t')\\nexplicit_hs = pd.read_csv('./datasets/isomers/isomers_explicit_hs.csv', sep='\\t')\\nkekulize = pd.read_csv('./datasets/isomers/isomers_kekulize.csv', sep='\\t')\\ncycle = pd.read_csv('./datasets/isomers/isomers_cycle.csv', sep='\\t')\\n\\n\\nfull_data = {'canonical': canonical, 'explicit_hs': explicit_hs, 'kekulize': kekulize, 'cycle': cycle}\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "gold = pd.read_csv('./datasets/isomers/smiles_qm9_isomers_found_new.csv', sep='\\t')\n",
    "\n",
    "canonical = pd.read_csv('./datasets/isomers/isomers_rdkit_canonical.csv', sep='\\t')\n",
    "explicit_hs = pd.read_csv('./datasets/isomers/isomers_explicit_hs.csv', sep='\\t')\n",
    "kekulize = pd.read_csv('./datasets/isomers/isomers_kekulize.csv', sep='\\t')\n",
    "cycle = pd.read_csv('./datasets/isomers/isomers_cycle.csv', sep='\\t')\n",
    "\n",
    "\n",
    "full_data = {'canonical': canonical, 'explicit_hs': explicit_hs, 'kekulize': kekulize, 'cycle': cycle}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main function of evaluation, it will get last hidden state from encoder or will use last hidden state of bert-like models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tokenizer, full_data=full_data):\n",
    "    \n",
    "    try:\n",
    "        orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "    except:\n",
    "        print('model mode')\n",
    "        orig_res = save_last_hidden_state_model(gold, model, tokenizer, 'orig')\n",
    "\n",
    "    for key, value in full_data.items():\n",
    "        try:\n",
    "            test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "        except:\n",
    "            print('model mode')\n",
    "            test = save_last_hidden_state_model(value, model, tokenizer, key)\n",
    "        x = create_dist_MRR(test, orig_res)\n",
    "        print(key)\n",
    "        print('MRR')\n",
    "        print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5054.42it/s]\n",
      "100%|██████████| 3300/3300 [04:57<00:00, 11.11it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5707.04it/s]\n",
      "100%|██████████| 3300/3300 [04:47<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.5090194203470724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4232.63it/s]\n",
      "100%|██████████| 3300/3300 [08:36<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.05474498500082556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5603.83it/s]\n",
      "100%|██████████| 3300/3300 [04:57<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.7086395625615578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5263.38it/s]\n",
      "100%|██████████| 3300/3300 [05:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9382382746514041\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"laituan245/molt5-base-smiles2caption\")\n",
    "model = AutoModel.from_pretrained('laituan245/molt5-base-smiles2caption')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4912.09it/s]\n",
      "100%|██████████| 3300/3300 [04:12<00:00, 13.08it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5145.77it/s]\n",
      "100%|██████████| 3300/3300 [04:05<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.6308568066328277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4592.09it/s]\n",
      "100%|██████████| 3300/3300 [07:02<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.0841488879516965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5481.18it/s]\n",
      "100%|██████████| 3300/3300 [04:07<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.7782348126385085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5290.26it/s]\n",
      "100%|██████████| 3300/3300 [04:09<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9842264309764309\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-standard\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-standard')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4519.57it/s]\n",
      "100%|██████████| 3300/3300 [04:52<00:00, 11.29it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3851.49it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4169.43it/s]\n",
      "100%|██████████| 3300/3300 [01:57<00:00, 28.16it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4292.60it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4037.88it/s]\n",
      "100%|██████████| 3300/3300 [01:51<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.33340564382390847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3348.45it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:01<00:00, 3015.92it/s]\n",
      "100%|██████████| 3300/3300 [02:57<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.02052281240060917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4473.04it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4413.58it/s]\n",
      "100%|██████████| 3300/3300 [01:56<00:00, 28.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.5412084946588809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4300.82it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4077.75it/s]\n",
      "100%|██████████| 3300/3300 [01:58<00:00, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9525582814522532\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "model = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5036.75it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5705.98it/s]\n",
      "100%|██████████| 3300/3300 [11:01<00:00,  4.99it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 5419.17it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5624.45it/s]\n",
      "100%|██████████| 3300/3300 [10:32<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.40255845404298085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3810.78it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4392.81it/s]\n",
      "100%|██████████| 3300/3300 [15:49<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.036401901897696445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5804.52it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5842.20it/s]\n",
      "100%|██████████| 3300/3300 [10:43<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.628572934778063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5443.52it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5743.74it/s]\n",
      "100%|██████████| 3300/3300 [11:40<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9785800347092214\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mschuh/PubChemDeBERTa-augmented\")\n",
    "model = AutoModel.from_pretrained('mschuh/PubChemDeBERTa-augmented')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at entropy/roberta_zinc_480m and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3300/3300 [07:09<00:00,  7.68it/s]\n",
      "100%|██████████| 3300/3300 [06:56<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.3319206577158926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [08:09<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.01690927781786464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [07:04<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.45584311454706455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [07:07<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.6918379029800314\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"entropy/roberta_zinc_480m\", max_len=128)# размерности тензоров не совпадают\n",
    "model = AutoModel.from_pretrained('entropy/roberta_zinc_480m')\n",
    "\n",
    "orig_res = save_last_hidden_state_bert(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_bert(value['SMILES'], model, tokenizer, key)\n",
    "    #x = create_dist(test, orig_res)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5805.89it/s]\n",
      "100%|██████████| 3300/3300 [15:50<00:00,  3.47it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 6249.46it/s]\n",
      "100%|██████████| 3300/3300 [14:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.5473938868323259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3864.55it/s]\n",
      "100%|██████████| 3300/3300 [26:21<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.04149201506590143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 6200.85it/s]\n",
      "100%|██████████| 3300/3300 [14:40<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.6719233680723551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 6221.20it/s]\n",
      "100%|██████████| 3300/3300 [16:24<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9906161616161616\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"laituan245/molt5-large-smiles2caption\")\n",
    "model = AutoModel.from_pretrained('laituan245/molt5-large-smiles2caption')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4697.87it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4521.47it/s]\n",
      "100%|██████████| 3300/3300 [04:40<00:00, 11.75it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4859.36it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4185.77it/s]\n",
      "100%|██████████| 3300/3300 [04:22<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.28842606254557684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4014.02it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3827.77it/s]\n",
      "100%|██████████| 3300/3300 [07:29<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.01499895818831797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5153.69it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5274.61it/s]\n",
      "100%|██████████| 3300/3300 [04:35<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.41692750948809054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5098.13it/s]\n",
      "  0%|          | 0/3300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4932.40it/s]\n",
      "100%|██████████| 3300/3300 [04:43<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.8001843020469118\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"entropy/gpt2_zinc_87m\", max_len=256) # ids out of range \n",
    "model = AutoModel.from_pretrained('entropy/gpt2_zinc_87m')\n",
    "test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jonghyunlee/ChemBERT_ChEMBL_pretrained and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3300/3300 [01:03<00:00, 51.89it/s]\n",
      "100%|██████████| 3300/3300 [01:02<00:00, 53.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.3222900363445153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:20<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.028572756379835283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:02<00:00, 52.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.4610637613875959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [01:03<00:00, 51.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.8320478471458127\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jonghyunlee/ChemBERT_ChEMBL_pretrained\", max_len=128) #256 max_length=128\n",
    "model = AutoModel.from_pretrained('jonghyunlee/ChemBERT_ChEMBL_pretrained')\n",
    "\n",
    "orig_res = save_last_hidden_state_bert(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_bert(value['SMILES'], model, tokenizer, key)\n",
    "    #x = create_dist(test, orig_res)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [14:54<00:00,  3.69it/s]\n",
      "100%|██████████| 3300/3300 [13:59<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.31844008784732564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [24:19<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.021607089132251917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [14:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.46937777487148913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [14:40<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.662280967138691\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gayane/BARTSmiles\", trust_remote_code=True, max_len=128)\n",
    "model = AutoModel.from_pretrained(\"gayane/BARTSmiles\", trust_remote_code=True)\n",
    "\n",
    "orig_res = save_last_hidden_state_bert(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_bert(value['SMILES'], model, tokenizer, key)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_last_hidden_state_t5(data, model, tokenizer, path_to_res): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t5_condgen_result = []\n",
    "        for batch in tqdm(data):\n",
    "            \n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", return_token_type_ids=False, padding=False, truncation=True)\n",
    "            output = model.encoder(input_ids=inputs, return_dict=True).last_hidden_state\n",
    "            t5_condgen_result.append(torch.mean(output, dim=1))\n",
    "\n",
    "    with open(path_to_res + '_hidden.pkl', 'wb') as f:\n",
    "        pickle.dump(t5_condgen_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4177.41it/s]\n",
      "100%|██████████| 3300/3300 [04:58<00:00, 11.05it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4511.02it/s]\n",
      "100%|██████████| 3300/3300 [04:45<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.72413124747378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3876.66it/s]\n",
      "100%|██████████| 3300/3300 [08:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.08569781859059095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 5661.77it/s]\n",
      "100%|██████████| 3300/3300 [04:43<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.8378026761797364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4768.37it/s]\n",
      "100%|██████████| 3300/3300 [04:49<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9817955781592146\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-standard\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-standard')\n",
    "model.eval()\n",
    "\n",
    "gold['SMILES'] = ['Caption the following SMILES: '+i for i in gold['SMILES']]\n",
    "orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    value['SMILES'] = ['Caption the following SMILES: '+i for i in value['SMILES']]\n",
    "    test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "    #x = create_dist(test, orig_res)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4211.78it/s]\n",
      "100%|██████████| 3300/3300 [05:16<00:00, 10.41it/s]\n",
      "100%|██████████| 3300/3300 [00:00<00:00, 4300.39it/s]\n",
      "100%|██████████| 3300/3300 [05:10<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.708984162496612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 3478.25it/s]\n",
      "100%|██████████| 3300/3300 [07:52<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.07115887116545133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4913.45it/s]\n",
      "100%|██████████| 3300/3300 [04:50<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.8438527616890797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:00<00:00, 4302.81it/s]\n",
      "100%|██████████| 3300/3300 [04:52<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9834855699855702\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GT4SD/multitask-text-and-chemistry-t5-base-augm\")\n",
    "model = AutoModel.from_pretrained('GT4SD/multitask-text-and-chemistry-t5-base-augm')\n",
    "model.eval()\n",
    "\n",
    "gold['SMILES'] = ['Caption the following SMILES: '+i for i in gold['SMILES']]\n",
    "orig_res = save_last_hidden_state_encoder(gold, model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    value['SMILES'] = ['Caption the following SMILES: '+i for i in value['SMILES']]\n",
    "    test = save_last_hidden_state_encoder(value, model, tokenizer, key)\n",
    "    #x = create_dist(test, orig_res)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [05:12<00:00, 10.56it/s]\n",
      "100%|██████████| 3300/3300 [05:04<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical\n",
      "MRR\n",
      "0.3995886613287398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [08:13<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicit_hs\n",
      "MRR\n",
      "0.02971949426139215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [04:58<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekulize\n",
      "MRR\n",
      "0.6240719026867979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [05:01<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "MRR\n",
      "0.9922323232323234\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"razent/SciFive-base-Pubmed\")\n",
    "model = AutoModel.from_pretrained(\"razent/SciFive-base-Pubmed\")\n",
    "\n",
    "orig_res = save_last_hidden_state_scifive(gold['SMILES'], model, tokenizer, 'orig')\n",
    "\n",
    "for key, value in full_data.items():\n",
    "    test = save_last_hidden_state_scifive(value['SMILES'], model, tokenizer, key)\n",
    "    x = create_dist_MRR(test, orig_res)\n",
    "    print(key)\n",
    "    print('MRR')\n",
    "    print(sum([1/(i+1) for i in x[-1]])/len(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
